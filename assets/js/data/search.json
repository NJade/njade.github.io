[ { "title": "Deep Learning for Computer Vision 11 Training Neural Networks", "url": "/posts/Deep_Learning_for_Computer_Vision_11/", "categories": "Deep Learning", "tags": "Deep Learning, Deep Learning for Computer Vision", "date": "2021-02-13 22:00:00 +0900", "snippet": "이 게시글은 미시간 대학의 Deep Learning for Computer Vision(EECS 498-007/598-005)를 보고 정리한 것입니다.Learning rate Schedules 매우 높은 learning rate를 설정하면 빠르게 발산한다. 낮은 learning rate를 설정하면 매우 느리게 수렴한다. 높은 learning rate를 설정하면 발산하지는 않으나 최적해를 찾지 못한다. 시작은 높은 learning rate를 사용하여 점점 줄여가는 방법을 사용한다.Step 첫 번째 방법은 step으로 일..." }, { "title": "Deep Learning for Computer Vision 10 Training Neural Networks", "url": "/posts/Deep_Learning_for_Computer_Vision_10/", "categories": "Deep Learning", "tags": "Deep Learning, Deep Learning for Computer Vision", "date": "2021-02-13 22:00:00 +0900", "snippet": "이 게시글은 미시간 대학의 Deep Learning for Computer Vision(EECS 498-007/598-005)를 보고 정리한 것입니다.Activation FunctionsSigmoid 0~1 사이로 확률로 해석됨. x가 매우 작거나 크면 grad가 사라지는 문제가 있음 결과가 모두 양수이다 &amp;gt; 여러 레이어를 거치면 x가 항상 양수이므로 grad가 항상 양수이거나 음수가 되며 지그재그로 학습되어 학습이 느려진다. &amp;gt; 미니배치가 도움이 된다. exp 함수의 비용이 비싸다.Tanh ..." }, { "title": "Deep Learning for Computer Vision 9 Hardware and Software", "url": "/posts/Deep_Learning_for_Computer_Vision_9/", "categories": "Deep Learning", "tags": "Deep Learning, Deep Learning for Computer Vision", "date": "2021-02-13 14:54:00 +0900", "snippet": "이 게시글은 미시간 대학의 Deep Learning for Computer Vision(EECS 498-007/598-005)를 보고 정리한 것입니다.Deep Learning Hardware 딥러닝이 발전하며 CPU에 비하여 GPU가 매우 크게 성장하였다. GPU는 CPU에 비해 코어 하나당 속도는 느리지만 매우 많은 코어가 있다. Nvida에서는 tensor core(TPU)와 같은 특별한 하드웨어도 추가하였다. 하드웨어 특성에 맞춰 2의 제곱형태의 행렬을 사용하는 것이 효율적이다. Nvida tensor core와..." }, { "title": "Deep Learning for Computer Vision 8 CNN Architectures", "url": "/posts/Deep_Learning_for_Computer_Vision_8/", "categories": "Deep Learning", "tags": "Deep Learning, Deep Learning for Computer Vision", "date": "2021-02-12 14:54:00 +0900", "snippet": "이 게시글은 미시간 대학의 Deep Learning for Computer Vision(EECS 498-007/598-005)를 보고 정리한 것입니다.AlexNet 8 layer (5 Convolutional + 3 Fully connected) 구조 pooling layer는 매우 적은 파라미터와 계산량을 사용하여 선호되었다. 대부분의 메모리와 floating point operation은 convolution layer에서 사용된다. 하지만 대부분의 파라미터는 fully connected layers에서 사용한다...." }, { "title": "Deep Learning for Computer Vision 7 Convolutional Networks", "url": "/posts/Deep_Learning_for_Computer_Vision_7/", "categories": "Deep Learning", "tags": "Deep Learning, Deep Learning for Computer Vision", "date": "2021-01-05 00:35:00 +0900", "snippet": "이 게시글은 미시간 대학의 Deep Learning for Computer Vision(EECS 498-007/598-005)를 보고 정리한 것입니다.Motivation 이전의 full connect linear model은 이미지의 구조를 표현할 수 없다. 예를 들어 2x2 이미지를 학습한다면 4x1으로 변경하여야 한다. 이를 해결하기 위해 구조적인 형태의 노드를 사용한다.Convolutional Network CIFAR10 데이터를 기준으로 이미지는 32x32x3의 형태를 가진다. 여기서 3은 depth 혹은 ch..." }, { "title": "JPA JPQL 2", "url": "/posts/JPA_JPQL_2/", "categories": "JPA", "tags": "JPA", "date": "2021-01-04 02:20:00 +0900", "snippet": "이 게시글은 인프런의 김영한님의 강의를 보고 정리한 것입니다.실전 예제의 팁 등을 제외한 코드는 첨부하지 않습니다. 강의를 봐주세요.경로 표현식 .을 통해 객체 그래프를 탐색하는 것 상태 필드: 단순 값을 저장하기 위한 필드, 경로 탐색의 끝, 더 이상 탐색은 불가능 연관 필드: 연관관계를 위한 필드 m.team &amp;gt; 단일 값 연관 필드: 대상이 엔티티, 묵시적 내부 조인이 발생하며 더 깊은 탐색이 가능 t.members &amp;gt; 컬렉션 값 연관 필드: 대상이 컬렉션, 묵시적 내부 조인이 발생하나 더..." }, { "title": "JPA JPQL 1", "url": "/posts/JPA_JPQL_1/", "categories": "JPA", "tags": "JPA", "date": "2021-01-03 23:10:00 +0900", "snippet": "이 게시글은 인프런의 김영한님의 강의를 보고 정리한 것입니다.실전 예제의 팁 등을 제외한 코드는 첨부하지 않습니다. 강의를 봐주세요.JPQL 소개 JPA는 JPQL 및 QueryDSL을 지원한다. 애플리케이션이 필요한 데이터만 DB에서 가져오려면 결국 SQL을 써야함. 이를 위해 JPA는 JPQL을 지원 JPQL은 엔티티 객체를 대상으로 쿼리 EntityManager에 createQuery를 통해 쿼리문을 날릴 수 있다. 테이블이 아닌 객체를 대상으로 하는 객체 지향 SQL이며 특정 DB에 종속되지 않는다.Crite..." }, { "title": "JPA Value Type", "url": "/posts/JPA_value_type/", "categories": "JPA", "tags": "JPA", "date": "2021-01-02 19:30:00 +0900", "snippet": "이 게시글은 인프런의 김영한님의 강의를 보고 정리한 것입니다.실전 예제의 팁 등을 제외한 코드는 첨부하지 않습니다. 강의를 봐주세요.기본값 타입엔티티 타입 @Entity 로 정의하는 객체 데이터가 변해도 식별자로 지속해서 추적 가능값 타입 int, String 등 단순히 값으로 사용하는 자바 기본 타입이나 객체 식별자가 없고 값만 있어 추적이 불가능기본값 타입 primitive 타입, wrapper 타입, String 생명주기를 엔티티에 의존 값 타입은 공유하면 안됨. &amp;gt; 회원 이름 변경 시 다른 회원..." }, { "title": "Deep Learning for Computer Vision 6 Backpropagation", "url": "/posts/Deep_Learning_for_Computer_Vision_6/", "categories": "Deep Learning", "tags": "Deep Learning, Deep Learning for Computer Vision", "date": "2020-12-22 00:00:00 +0900", "snippet": "이 게시글은 미시간 대학의 Deep Learning for Computer Vision(EECS 498-007/598-005)를 보고 정리한 것입니다.Backpropagation Loss를 w로 미분하여 gradient를 계산하는 것은 매우 많은 계산이 필요하며 로스가 바뀌면 다시 계산하여야 한다. 즉 유연하게 확장이나 로스 변경이 불가능하다. 다음으로 나온 아이디어는 Computational Graphs이다. 예를 들어 f(x,y,z) = (x+y)*z 인 경우 우선 순전파(Forward pass)를 계산한다. - ..." }, { "title": "JPA Proxy and Relation", "url": "/posts/JPA_proxy_and_relation/", "categories": "JPA", "tags": "JPA", "date": "2020-12-17 01:30:00 +0900", "snippet": "이 게시글은 인프런의 김영한님의 강의를 보고 정리한 것입니다.실전 예제의 팁 등을 제외한 코드는 첨부하지 않습니다. 강의를 봐주세요.프록시 연관관계에 있는 객체를 함꼐 가져올 것인지 나중에 가져올 것인지 정해야 할 필요가 있다. 이런 로직을 위해 JPA에서 em.find()가 아닌 em.getReference()를 제공한다. em.getReference()는 DB조회를 미루는 프록시 엔티티 객체를 조회한다. 프록시는 실제 클래스를 상속 받아서 만들어짐. 프록시는 실제 클래스인 target을 가지고 있음. 실제 클래스..." }, { "title": "JPA Relation 3", "url": "/posts/JPA_relation_3/", "categories": "JPA", "tags": "JPA", "date": "2020-12-16 22:50:00 +0900", "snippet": "이 게시글은 인프런의 김영한님의 강의를 보고 정리한 것입니다.실전 예제의 팁 등을 제외한 코드는 첨부하지 않습니다. 강의를 봐주세요.상속관계 맵핑 RDB는 상속 관계가 없음. 슈퍼타입 서브타입 관계가 객체 상속과 유사하여 객체의 상속관계를 슈퍼타입 서브타입으로 맵핑 슈퍼타입 서브타입 DB 구현전략 조인 전략: 슈퍼타입과 서브타입의 PK가 같고 슈퍼타입에 서브타입의 타입을 기록하는 컬럼을 설정 단일 테이블 전략: 하나의 테이블에 모든 서브타입을 넣고 서브타입의 타입을 기록 구현 클래스마다 ..." }, { "title": "JPA Relation 2", "url": "/posts/JPA_relation_2/", "categories": "JPA", "tags": "JPA", "date": "2020-12-16 00:25:00 +0900", "snippet": "이 게시글은 인프런의 김영한님의 강의를 보고 정리한 것입니다.실전 예제의 팁 등을 제외한 코드는 첨부하지 않습니다. 강의를 봐주세요.다양한 연관관계 맵핑 연관관계 맵핑시 고려사항 3가지 다대일 [N:1] 일대다 [1:N] 일대일 [1:1] 다대다 [N:N]연관관계 맵핑시 고려사항 3가지다중성 다대일: @ManyToOne 일대다: @OneToMany 일대일: @OneToOne 다대다: @ManyToMany &amp;gt; 실무에서 사용하지 말 것단방향, 양방향 테이블: 외래 키 하나로 양쪽 조인이 가능한 방향이..." }, { "title": "Deep Learning for Computer Vision 5 Neural Network", "url": "/posts/Deep_Learning_for_Computer_Vision_5/", "categories": "Deep Learning", "tags": "Deep Learning, Deep Learning for Computer Vision", "date": "2020-12-09 23:00:00 +0900", "snippet": "이 게시글은 미시간 대학의 Deep Learning for Computer Vision(EECS 498-007/598-005)를 보고 정리한 것입니다.Motivation linear classifiers는 매우 간단하고 이해하기 쉽다. 하지만 성능은 충분히 좋지 않다. 예를 들어 데이터가 원형으로 분리되어 있는 경우 선형 분류기로는 분리할 수 없다. 또한 다른 형태의 같은 객체를 파악하기 어렵다. 데이터를 feature engineering을 통해 데이터를 feature space로 변환한다면 선형 분류기로 해결할 수..." }, { "title": "JPA Relation 1", "url": "/posts/JPA_relation_1/", "categories": "JPA", "tags": "JPA", "date": "2020-12-09 05:30:00 +0900", "snippet": "이 게시글은 인프런의 김영한님의 강의를 보고 정리한 것입니다.실전 예제의 팁 등을 제외한 코드는 첨부하지 않습니다. 강의를 봐주세요.연관관계 맵핑 기초 객체의 참조와 테이블의 외래키를 맵핑 방향: 단방향, 양방향 다중성: 다대일, 일대다, 일대일, 다대다 연관관계의 주인 Entity를 중심으로 ManyToOne, OneToMany를 선언 ManyToOne 선언시 @JoinColumn을 통해 FK 선언이 필요 OneToMany 선언시 mappedBy property를 상대 entity의 이름으로 선언해주어..." }, { "title": "Deep Learning for Computer Vision 4 Optimization", "url": "/posts/Deep_Learning_for_Computer_Vision_4/", "categories": "Deep Learning", "tags": "Deep Learning, Deep Learning for Computer Vision", "date": "2020-12-06 18:00:00 +0900", "snippet": "이 게시글은 미시간 대학의 Deep Learning for Computer Vision(EECS 498-007/598-005)를 보고 정리한 것입니다.Optimization w^* = argmin_w(L(w)) &amp;gt; loss를 최소화하는 w를 찾는 것찾는 방법Random Search 랜덤으로 w를 뽑으며 loss를 최소한으로 하는 w를 찾는 것 정확도는 나쁘지 않지만(15%) sota(95%)에 비하면 매우 나쁘다.Follow the slope 현재 있는 곳에서 내려가는 곳으로 생각되는 곳으로 진행 이 과정..." }, { "title": "JPA entity 맵핑", "url": "/posts/JPA_entrity_mapping/", "categories": "JPA", "tags": "JPA", "date": "2020-12-03 23:00:00 +0900", "snippet": "이 게시글은 인프런의 김영한님의 강의를 보고 정리한 것입니다.실전 예제의 팁 등을 제외한 코드는 첨부하지 않습니다. 강의를 봐주세요.엔티티 맵핑 소개 객체와 테이블 맵핑: @Entity, @Table 필드와 컬럼 맵핑: @Column 기본키 맵핑: @Id 연관관계 맵핑: @ManyToOne, @JoinColumn객체와 테이블 맵핑 @Entity가 붙은 클래시는 JPA가 관리하고 엔티티라고 한다. JPA를 사용해서 테이블과 맵핑한다면 @Entity가 필수 기본 생성자는 필수 (public or protected) ..." }, { "title": "Deep Learning for Computer Vision 3 Linear Classifiers", "url": "/posts/Deep_Learning_for_Computer_Vision_3/", "categories": "Deep Learning", "tags": "Deep Learning, Deep Learning for Computer Vision", "date": "2020-11-29 23:07:00 +0900", "snippet": "이 게시글은 미시간 대학의 Deep Learning for Computer Vision(EECS 498-007/598-005)를 보고 정리한 것입니다.Linear Classifier Linear Classifier를 쌓은 것이 Neural Network가 된다. CIFAR10(50000 train data, 10000 test data, 32x32x3 image) 데이터를 사용할 계획이다.Algebraic Viewpoint f(x, W)로 표시될 것이며 W는 가중치 혹은 파라미터라고 표현한다. f(x, W) = Wx +..." }, { "title": "Deep Learning for Computer Vision 2 Image Classification", "url": "/posts/Deep_Learning_for_Computer_Vision_2/", "categories": "Deep Learning", "tags": "Deep Learning, Deep Learning for Computer Vision", "date": "2020-11-29 23:07:00 +0900", "snippet": "이 게시글은 미시간 대학의 Deep Learning for Computer Vision(EECS 498-007/598-005)를 보고 정리한 것입니다.Image Classification 이미지가 주어지면 어떤 것의 이미지인가 분류하는 것. 컴퓨터는 픽셀 크기와 색 채널로 분류 함. (800x600x3) 배경색, 조명, 일부분만 노출되는 등이 어려움으로 존재. 이미지에 여러개의 object가 있는 경우 등도 존재할 수 있음 &amp;gt; Image Detection 문제로 확장됌. 과거에는 edge를 찾는 등의 문제..." }, { "title": "Deep Learning for Computer Vision 1 Introduction", "url": "/posts/Deep_Learning_for_Computer_Vision_1/", "categories": "Deep Learning", "tags": "Deep Learning, Deep Learning for Computer Vision", "date": "2020-11-29 23:00:00 +0900", "snippet": "이 게시글은 미시간 대학의 Deep Learning for Computer Vision(EECS 498-007/598-005)를 보고 정리한 것입니다.Deep Learning for Computer Vision 딥러닝을 공부하는 경우 많이들 보게 되는 스탠포드의 cs231n의 강사님인 Justin Johnson님이 미시간 대학으로 옮기시며 2019년 강의를 유투브에 업로드하셨습니다. 2017년도의 스탠포드 강의와 다르게 모든 과제는 pytorch 기반으로 진행된다고 하는데 강의를 보며 정리 및 과제를 진행할 계획입니다.In..." }, { "title": "JPA 영속성", "url": "/posts/JPA_persist/", "categories": "JPA", "tags": "JPA", "date": "2020-09-25 01:00:00 +0900", "snippet": "이 게시글은 인프런의 김영한님의 강의를 보고 정리한 것입니다.영속성 컨텍스트란 엔티티를 영구 저장하는 환경 영속성 컨텍스트는 논리적인 개념 엔티티 생명주기 비영속 (new/transient): 영속성 컨텍스트와 무관한 상태 영속 (managed): 영속성 컨텍스트에 관리되는 상태 준영속 (detached): 영속성 컨텍스트에 저장되었다가 분리된 상태 삭제 (removed): 삭제된 상태 Member member = new Member() // 비영속 상태em.persis..." }, { "title": "JPA 기본", "url": "/posts/JPA_basic/", "categories": "JPA", "tags": "JPA", "date": "2020-09-24 23:21:00 +0900", "snippet": "이 게시글은 인프런의 김영한님의 강의를 보고 정리한 것입니다.JPA 기본 설정 JPA를 사용하기 위해서는 persistence.xml이 필요.(DB 및 여러 설정을 해줌) dialect(방언) - 각 DB마다 비표준 문법이 존재하여 이를 위한 설정 필요&amp;lt;property name=&quot;hibernate.dialect&quot; value=&quot;org.hibernate.dialect.H2Dialect&quot;/&amp;gt;구조 Persistence가 EntityManagerFactory를 생성하면 ..." } ]
